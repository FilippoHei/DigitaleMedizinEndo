{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8458bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e38e6a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "# Change this path to wherever you installed the Pytorch-UNet module\n",
    "sys.path.append(r\"C:\\Users\\Groh\\Documents\\GitHub\\unet-nested-multiple-classification\")\n",
    "# sys.path.append(r\"C:\\Users\\Groh\\Documents\\GitHub\\colabtools\\google\")\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import functional as func\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from unet import NestedUNet\n",
    "from unet import UNet\n",
    "from utils.dataset import BasicDataset\n",
    "from config import UNetConfig\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# os.chdir(\"/content/drive/My Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad8abf8",
   "metadata": {},
   "source": [
    "### Load image directories and u-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "020494cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount of Input images: 223\n"
     ]
    }
   ],
   "source": [
    "dir_img = r\"C:\\Users\\Groh\\Desktop\\TrainingDigEndo\\images_training\"\n",
    "dir_mask = r\"C:\\Users\\Groh\\Desktop\\TrainingDigEndo\\masks_grayscale\"\n",
    "checkpoint = r\"C:\\Users\\Groh\\Desktop\\TrainingDigEndo\\Checkpoints\\checkpoints_training05-02\\epoch_100.pth\"\n",
    "sessions_to_test = [\"03\",\"04\"]\n",
    "\n",
    "cfg = UNetConfig()\n",
    "net = eval(cfg.model)(cfg)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net.to(device=device)\n",
    "net.load_state_dict(torch.load(checkpoint, map_location=device))\n",
    "\n",
    "input_imgs = [i for i in os.listdir(dir_img) if os.path.isfile(os.path.join(dir_img,i)) and \\\n",
    "     i.startswith(tuple([\"aicm\"+ses for ses in sessions_to_test]))]\n",
    "print(\"\\nAmount of Input images: {}\".format(len(input_imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb9f11f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def eval_net(net, loader, device, n_val, cfg):\n",
    "    net.eval()\n",
    "    tot = 0\n",
    "\n",
    "    with tqdm(total=n_val, desc='Validation round', unit='img', leave=False) as pbar:\n",
    "        for batch in loader:\n",
    "            imgs = batch['image']\n",
    "            true_masks = batch['mask']\n",
    "\n",
    "            imgs = imgs.to(device=device, dtype=torch.float32)\n",
    "            mask_type = torch.float32 if cfg.n_classes == 1 else torch.long\n",
    "            true_masks = true_masks.to(device=device, dtype=mask_type)\n",
    "\n",
    "            # compute loss\n",
    "            if cfg.deepsupervision:\n",
    "                masks_preds = net(imgs)\n",
    "                loss = 0\n",
    "                for masks_pred in masks_preds:\n",
    "                    tot_cross_entropy = 0\n",
    "                    for true_mask, pred in zip(true_masks, masks_pred):\n",
    "                        pred = (pred > cfg.out_threshold).float()\n",
    "                        if cfg.n_classes > 1:\n",
    "                            sub_cross_entropy = F.cross_entropy(pred.unsqueeze(dim=0), true_mask.unsqueeze(dim=0).squeeze(1)).item()\n",
    "                        else:\n",
    "                            sub_cross_entropy = dice_coeff(pred, true_mask.squeeze(dim=1)).item()\n",
    "                        tot_cross_entropy += sub_cross_entropy\n",
    "                    tot_cross_entropy = tot_cross_entropy / len(masks_preds)\n",
    "                    tot += tot_cross_entropy\n",
    "            else:\n",
    "                masks_pred = net(imgs)\n",
    "                for true_mask, pred in zip(true_masks, masks_pred):\n",
    "                    pred = (pred > cfg.out_threshold).float()\n",
    "                    if cfg.n_classes > 1:\n",
    "                        tot += F.cross_entropy(pred.unsqueeze(dim=0), true_mask.unsqueeze(dim=0).squeeze(1)).item()\n",
    "                    else:\n",
    "                        tot += dice_coeff(pred, true_mask.squeeze(dim=1)).item()\n",
    "\n",
    "            pbar.update(imgs.shape[0])\n",
    "\n",
    "    return tot / n_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f387a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function generates prediction masks\n",
    "def inference_one(net, image, device):\n",
    "    net.eval()\n",
    "    \n",
    "    image_array = np.array(image)\n",
    "    image_array = image_array.transpose((2,0,1))\n",
    "    img = torch.from_numpy(image_array)\n",
    "\n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.to(device=device, dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = net(img)\n",
    "        if cfg.deepsupervision:\n",
    "            output = output[-1]\n",
    "\n",
    "        if cfg.n_classes > 1:\n",
    "            probs = F.softmax(output, dim=1)\n",
    "        else:\n",
    "            probs = torch.sigmoid(output)\n",
    "\n",
    "        probs = probs.squeeze(0)\n",
    "\n",
    "        tf = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((image.size[1], image.size[0])),\n",
    "                transforms.ToTensor()\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        if cfg.n_classes == 1:\n",
    "            probs = tf(probs.cpu())\n",
    "            mask = probs.squeeze().cpu().numpy()\n",
    "            return mask > cfg.out_threshold\n",
    "        else:\n",
    "            masks = []\n",
    "            for prob in probs:\n",
    "                prob = tf(prob.cpu())\n",
    "                mask = prob.squeeze().cpu().numpy()\n",
    "                mask = mask > cfg.out_threshold\n",
    "                masks.append(mask)\n",
    "            return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d5629a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSelectedFilenames(directory, sessions):\n",
    "    all_filenames = list(sorted(os.listdir(directory)));\n",
    "    selected_filenames = []\n",
    "  \n",
    "    for session in sessions:\n",
    "        string = 'aicm' + session\n",
    "        for name in all_filenames:\n",
    "            if string in name:\n",
    "                selected_filenames.append(name)\n",
    "    \n",
    "    return selected_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75368fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_variability(masks_predic, mask_true):\n",
    "        # Check whether both images have the same input shape\n",
    "        if masks_predic[0].shape != mask_true.shape:\n",
    "            raise ValueError(\"The two masks have different shapes. Please adjust the shapes accordingly.\")\n",
    "        else:\n",
    "            \n",
    "            intersection=0\n",
    "            union=0\n",
    "            \n",
    "            # Calculate the intersection and the union of both masks\n",
    "            for i in range(mask_true.shape[0]):\n",
    "                for j in range(mask_true.shape[1]):\n",
    "                    if any(element[i][j] for element in masks_predic[1:]) and mask_true[i][j]:\n",
    "                        intersection+=1\n",
    "                    if any(element[i][j] for element in masks_predic[1:]) or mask_true[i][j]:\n",
    "                        union+=1       \n",
    "            \n",
    "            # Return dice score, as well as intersection over union (iou)\n",
    "            # Quality metrics don't make sense, when the given class is not visible, hence the NaNs.\n",
    "            if not mask_true.any():\n",
    "                dice = np.NaN\n",
    "                iou = np.NaN\n",
    "            else:\n",
    "                dice = (2. * intersection)/(np.sum(np.array(masks_predic[1:])) + mask_true.sum())\n",
    "                iou = intersection/union\n",
    "        return dice, iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0b052e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variability(mask_predic, mask_true):\n",
    "        # Check whether both images have the same input shape\n",
    "        if mask_predic.shape != mask_true.shape:\n",
    "            raise ValueError(\"The two masks have different shapes. Please adjust the shapes accordingly.\")\n",
    "        else:\n",
    "            \n",
    "            intersection=0\n",
    "            union=0\n",
    "            \n",
    "            # Calculate the intersection and the union of both masks\n",
    "            for i in range(mask_true.shape[0]):\n",
    "                for j in range(mask_true.shape[1]):\n",
    "                    if mask_predic[i][j] and mask_true[i][j]:\n",
    "                        intersection+=1\n",
    "                    if mask_predic[i][j] or mask_true[i][j]:\n",
    "                        union+=1       \n",
    "            \n",
    "            # Return dice score, as well as intersection over union (iou)\n",
    "            # Quality metrics don't make sense, when the given class is not visible, hence the NaNs.\n",
    "            if not mask_true.any():\n",
    "                dice = np.NaN\n",
    "                iou = np.NaN\n",
    "            else:\n",
    "                dice = (2. * intersection)/(mask_predic.sum() + mask_true.sum())\n",
    "                iou = intersection/union\n",
    "        return dice, iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68196c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images_directory, masks_directory, sessions, transform=None):  \n",
    "        self.images_filenames = getSelectedFilenames(images_directory, sessions)\n",
    "        self.images_directory = images_directory\n",
    "        self.masks_directory = masks_directory\n",
    "        self.transform = transform\n",
    "        self.sessions = sessions          \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filename = self.images_filenames[idx]\n",
    "\n",
    "        pathImage = os.path.join(self.images_directory, image_filename);\n",
    "        pathMask = os.path.join(self.masks_directory, image_filename);\n",
    "        \n",
    "        pillow_image = Image.open(pathImage)\n",
    "        image = np.array(pillow_image)\n",
    "        pillow_mask = Image.open(pathMask).convert('L')\n",
    "        mask = np.array(pillow_mask)\n",
    "                \n",
    "        if self.transform is not None:\n",
    "            transformed = self.transform(image=image, mask=mask)\n",
    "            image = transformed[\"image\"]\n",
    "            mask = transformed[\"mask\"]\n",
    "            image = np.array(image)\n",
    "            mask = np.array(mask)\n",
    "        \n",
    "        mask = torch.from_numpy(mask)\n",
    "        mask = mask.unsqueeze(0)\n",
    "        \n",
    "        image = image.transpose((2,0,1))\n",
    "        image = torch.from_numpy(image)\n",
    "\n",
    "\n",
    "        return {\n",
    "            'image': image,\n",
    "            'mask':  mask\n",
    "        } \n",
    "\n",
    "    def preprocess(cls, pil_img, scale):\n",
    "        w, h = pil_img.size\n",
    "        newW, newH = int(scale * w), int(scale * h)\n",
    "        assert newW > 0 and newH > 0, 'Scale is too small'\n",
    "        pil_img = pil_img.resize((newW, newH))\n",
    "\n",
    "        img_nd = np.array(pil_img)\n",
    "\n",
    "        if len(img_nd.shape) == 2:\n",
    "            img_nd = np.expand_dims(img_nd, axis=2)\n",
    "\n",
    "        # HWC to CHW\n",
    "        img_trans = img_nd.transpose((2, 0, 1))\n",
    "        if img_trans.max() > 1:\n",
    "            img_trans = img_trans / 255\n",
    "\n",
    "        return img_trans         \n",
    "        \n",
    "val_dataset = CustomDataset(dir_img, dir_mask, sessions_to_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144188bf",
   "metadata": {},
   "source": [
    "### Evaluate Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "526df281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1169132915045648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "n_val = len(val_dataset)\n",
    "val = val_dataset\n",
    "\n",
    "val_loader = DataLoader(val,\n",
    "                        batch_size=cfg.batch_size,\n",
    "                        shuffle=False,\n",
    "                        num_workers=0,\n",
    "                        pin_memory=True)\n",
    "\n",
    "val_score = eval_net(net, val_loader, device, n_val, cfg)\n",
    "\n",
    "print(val_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408c440f",
   "metadata": {},
   "source": [
    "### Binary Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af17df53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image aicm03_02_000002.png --- Dice Score: 0.22173 | IOU: 0.12469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:06,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image aicm03_02_000004.png --- Dice Score: 0.00000 | IOU: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:08,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image aicm03_02_000006.png --- Dice Score: 0.48272 | IOU: 0.31814\n"
     ]
    }
   ],
   "source": [
    "# Preallocate arrays\n",
    "total_dice = np.zeros(int(len(input_imgs)))\n",
    "total_dice[:] = np.NaN                  \n",
    "total_iou = np.zeros(int(len(input_imgs)))\n",
    "total_iou[:] = np.NaN     \n",
    "\n",
    "img_count = 0\n",
    "for i, img_name in tqdm(enumerate(input_imgs)):\n",
    "    img_path = osp.join(dir_img, img_name)\n",
    "    img = Image.open(img_path)\n",
    "\n",
    "    mask = inference_one(net=net,\n",
    "                         image=img,\n",
    "                         device=device)\n",
    "\n",
    "    img = cv2.imread(os.path.join(dir_mask, img_name), cv2.IMREAD_GRAYSCALE)\n",
    "    mask_true = img != 0\n",
    "\n",
    "    dice, iou = binary_variability(mask, mask_true)\n",
    "    total_dice[img_count] = dice\n",
    "    total_iou[img_count] = iou\n",
    "    \n",
    "    print(\"Image {} --- Dice Score: {:.5f} | IOU: {:.5f}\".format(img_name, dice, iou))\n",
    "    img_count += 1\n",
    "\n",
    "print(\"\\nAverage Binary Dice Score: {:.4f} (STD: {:.4f})\".format(np.nanmean(total_dice), np.nanstd(total_dice)))\n",
    "print(\"Average Binary IOU: {:.4f} (STD: {:.4f})\".format(np.nanmean(total_iou), np.nanstd(total_iou)))\n",
    "q75, q25 = np.nanpercentile(total_dice, [75 ,25])\n",
    "print(\"\\nMedian Binary Dice Score: {:.4f} (IQR: {:.4f}, {:.4f})\".format(np.nanmedian(total_dice), q75, q25))\n",
    "q75, q25 = np.nanpercentile(total_iou, [75 ,25])\n",
    "print(\"Median Binary IOU: {:.4f} (IQR: {:.4f}, {:.4f})\".format(np.nanmedian(total_iou), q75, q25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8462282",
   "metadata": {},
   "source": [
    "### Multi-Class Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88b08ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preallocate arrays\n",
    "total_dice = np.zeros((cfg.n_classes, int(len(input_imgs))))\n",
    "total_dice[:] = np.NaN                  \n",
    "total_iou = np.zeros((cfg.n_classes, int(len(input_imgs))))\n",
    "total_iou[:] = np.NaN     \n",
    "\n",
    "img_count = 0\n",
    "for i, img_name in tqdm(enumerate(input_imgs)):\n",
    "    img_path = osp.join(dir_img, img_name)\n",
    "    img = Image.open(img_path)\n",
    "\n",
    "    mask = inference_one(net=net,\n",
    "                         image=img,\n",
    "                         device=device)\n",
    "    for idx in range(0,len(mask)):\n",
    "        img = cv2.imread(os.path.join(dir_mask, img_name), cv2.IMREAD_GRAYSCALE)\n",
    "        mask_true = img == idx\n",
    "        mask_predic = mask[idx]\n",
    "        dice, iou = variability(mask_predic, mask_true)\n",
    "        total_dice[idx,img_count] = dice\n",
    "        total_iou[idx,img_count] = iou\n",
    "        print(\"Image {}, Class {} --- Dice Score: {:.5f} | IOU: {:.5f}\".format(img_name, idx, dice, iou))\n",
    "    img_count += 1\n",
    "\n",
    "for idx in range(0,cfg.n_classes):\n",
    "    print(\"\\nAverage Dice Score for Class {}: {:.4f} (STD: {:.4f})\".format(idx, np.nanmean(total_dice[idx]), np.nanstd(total_dice[idx])))\n",
    "    print(\"Average IOU for Class {}: {:.4f} (STD: {:.4f})\".format(idx, np.nanmean(total_iou[idx]), np.nanstd(total_iou[idx])))\n",
    "    q75, q25 = np.nanpercentile(total_dice[idx], [75 ,25])\n",
    "    print(\"\\nMedian Dice Score for Class {}: {:.4f} (IQR: {:.4f}, {:.4f})\".format(idx, np.nanmedian(total_dice[idx]), q75, q25))\n",
    "    q75, q25 = np.nanpercentile(total_iou[idx], [75 ,25])\n",
    "    print(\"Median IOU for Class {}: {:.4f} (IQR: {:.4f}, {:.4f})\".format(idx, np.nanmedian(total_iou[idx]), q75, q25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16ea1cd",
   "metadata": {},
   "source": [
    "### Save predicted masks"
   ]
  },
  {
   "cell_type": "raw",
   "id": "45f45303",
   "metadata": {},
   "source": [
    "# If you want to save inference masks, use this cell\n",
    "output_dir = \"./path/to/output/dir\"\n",
    "\n",
    "for i, img_name in tqdm(enumerate(input_imgs)):\n",
    "    img_path = osp.join(dir_img, img_name)\n",
    "    img = Image.open(img_path)\n",
    "\n",
    "    mask = inference_one(net=net,\n",
    "                         image=img,\n",
    "                         device=device)\n",
    "    img_name_no_ext = osp.splitext(img_name)[0]\n",
    "    output_img_dir = osp.join(output_dir, img_name_no_ext)\n",
    "    os.makedirs(output_img_dir, exist_ok=True)\n",
    "\n",
    "    if cfg.n_classes == 1:\n",
    "        image_idx = Image.fromarray((mask * 255).astype(np.uint8))\n",
    "        image_idx.save(osp.join(output_img_dir, img_name))\n",
    "    else:\n",
    "        for idx in range(0, len(mask)):\n",
    "            img_name_idx = img_name_no_ext + \"_\" + str(idx) + \".png\"\n",
    "            image_idx = Image.fromarray((mask[idx] * 255).astype(np.uint8))\n",
    "            image_idx.save(osp.join(output_img_dir, img_name_idx))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
