{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ac3264",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d6650d",
   "metadata": {},
   "source": [
    "#### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b22edfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Change this path to wherever you installed the Pytorch-UNet module\n",
    "sys.path.append('C:/Users/Groh/Documents/GitHub/Pytorch-UNet')\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from eval import eval_net\n",
    "from unet import UNet\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils.dataset import BasicDataset\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44eaf03",
   "metadata": {},
   "source": [
    "#### Assing absolute paths of image and mask folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e553b737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this path to the respective image and mask folders\n",
    "dir_img = 'C:/Users/Groh/Documents/GitHub/Pytorch-UNet/data/images/'\n",
    "dir_mask = 'C:/Users/Groh/Documents/GitHub/Pytorch-UNet/data/masks/'\n",
    "dir_checkpoint = 'C:/Users/Groh/Documents/GitHub/Pytorch-UNet/checkpoints/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373e6606",
   "metadata": {},
   "source": [
    "#### Prepare masks for multi instance segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca8a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_files = len([f for f in os.listdir(dir_img)if os.path.isfile(os.path.join(dir_img, f))])\n",
    "\n",
    "for i in range(num_files):\n",
    "    name = os.listdir(dir_img)[i]\n",
    "    file = dir_mask+name\n",
    "    \n",
    "    # If a mask is missing, create a new, empty mask\n",
    "    if not os.path.isfile(file):\n",
    "        img = Image.open(dir_img+name)\n",
    "        width, height = img.size\n",
    "\n",
    "        img_new = Image.new('L', (width, height))\n",
    "        img_new.save(file, \"PNG\")\n",
    "    \n",
    "    # Convert all images to 8-bit gray scales\n",
    "    img_grayscale = Image.open(file).convert('L')\n",
    "    img_grayscale.save(file)\n",
    "    \n",
    "    \n",
    "    # Check, whether more than background is visible in the mask\n",
    "    image_gray = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    unique = np.unique(image_gray.flatten())\n",
    "    if len(unique) > 1:\n",
    "        # For every pixel change gray-scale value according to categorical value\n",
    "        img = Image.open(file)\n",
    "        # Create pixel map\n",
    "        pixels = img.load()\n",
    "        for ii in range(img.size[0]): \n",
    "            for j in range(img.size[1]):\n",
    "                if pixels[ii,j] == 52: # Atraum. Pinzette\n",
    "                    pixels[ii,j] = 1\n",
    "                elif pixels[ii,j] == 113: # Nadelhalter\n",
    "                    pixels[ii,j] = 2\n",
    "#                     elif pixels[i,j] = 52:\n",
    "#                         pixels[i,j] = 1\n",
    "#                     elif pixels[i,j] = 52:\n",
    "#                         pixels[i,j] = 1\n",
    "#                     elif pixels[i,j] = 52:\n",
    "#                         pixels[i,j] = 1\n",
    "#                     elif pixels[i,j] = 52:\n",
    "#                         pixels[i,j] = 1\n",
    "#                     elif pixels[i,j] = 52:\n",
    "#                         pixels[i,j] = 1\n",
    "\n",
    "    \n",
    "    ### Only for binary segmentation\n",
    "    #img_grayscale = Image.open(file)\n",
    "    #thresh = 10\n",
    "    #fn = lambda x : 255 if x > thresh else 0\n",
    "    #r = img_grayscale.convert('L').point(fn, mode='1')\n",
    "    #r.save(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "df4ffd36",
   "metadata": {},
   "source": [
    "for i in range(num_files):\n",
    "    name = os.listdir(dir_img)[i]\n",
    "    file = dir_mask+name\n",
    "   \n",
    "    \n",
    "    image_gray = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    unique = np.unique(image_gray.flatten())\n",
    "    \n",
    "    img = Image.open(file)\n",
    "    img_array = np.array(img)\n",
    "    pictype = img_array.dtype\n",
    "    \n",
    "    print(unique, pictype)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e23ab44",
   "metadata": {},
   "source": [
    "img = Image.open(dir_img+name)\n",
    "\n",
    "img_array = np.array(img)\n",
    "\n",
    "pictype = img_array.dtype\n",
    "\n",
    "picchannels = img_array.shape\n",
    "\n",
    "print(pictype, picchannels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecc6ada",
   "metadata": {},
   "source": [
    "#### Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5523fc5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_net(net,\n",
    "              device,\n",
    "              epochs=5,\n",
    "              batch_size=1,\n",
    "              lr=0.001,\n",
    "              val_percent=0.1,\n",
    "              save_cp=True,\n",
    "              img_scale=0.5):\n",
    "\n",
    "    dataset = BasicDataset(dir_img, dir_mask, img_scale)\n",
    "    n_val = int(len(dataset) * val_percent)\n",
    "    n_train = len(dataset) - n_val\n",
    "    train, val = random_split(dataset, [n_train, n_val])\n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "    val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True, drop_last=True)\n",
    "\n",
    "    writer = SummaryWriter(comment=f'LR_{lr}_BS_{batch_size}_SCALE_{img_scale}')\n",
    "    global_step = 0\n",
    "\n",
    "    logging.info(f'''Starting training:\n",
    "        Epochs:          {epochs}\n",
    "        Batch size:      {batch_size}\n",
    "        Learning rate:   {lr}\n",
    "        Training size:   {n_train}\n",
    "        Validation size: {n_val}\n",
    "        Checkpoints:     {save_cp}\n",
    "        Device:          {device.type}\n",
    "        Images scaling:  {img_scale}\n",
    "    ''')\n",
    "\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=lr, weight_decay=1e-8, momentum=0.9)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min' if net.n_classes > 1 else 'max', patience=2)\n",
    "    \n",
    "    # Use Binary Cross Entropy as loss function, if more than one class is used\n",
    "    if net.n_classes > 1:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    # Use a plain Sigmoid and Binary Cross Entropy as loss function\n",
    "    else:\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "\n",
    "        epoch_loss = 0\n",
    "        with tqdm(total=n_train, desc=f'Epoch {epoch + 1}/{epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                imgs = batch['image']\n",
    "                true_masks = batch['mask']\n",
    "                assert imgs.shape[1] == net.n_channels, \\\n",
    "                    f'Network has been defined with {net.n_channels} input channels, ' \\\n",
    "                    f'but loaded images have {imgs.shape[1]} channels. Please check that ' \\\n",
    "                    'the images are loaded correctly.'\n",
    "\n",
    "                imgs = imgs.to(device=device, dtype=torch.float32)\n",
    "                mask_type = torch.float32 if net.n_classes == 1 else torch.long\n",
    "                true_masks = true_masks.to(device=device, dtype=mask_type)\n",
    "\n",
    "                masks_pred = net(imgs)\n",
    "                loss = criterion(masks_pred, true_masks)\n",
    "                epoch_loss += loss.item()\n",
    "                writer.add_scalar('Loss/train', loss.item(), global_step)\n",
    "\n",
    "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_value_(net.parameters(), 0.1)\n",
    "                optimizer.step()\n",
    "\n",
    "                pbar.update(imgs.shape[0])\n",
    "                global_step += 1\n",
    "                if global_step % (n_train // (10 * batch_size)) == 0:\n",
    "                    for tag, value in net.named_parameters():\n",
    "                        tag = tag.replace('.', '/')\n",
    "                        writer.add_histogram('weights/' + tag, value.data.cpu().numpy(), global_step)\n",
    "                        writer.add_histogram('grads/' + tag, value.grad.data.cpu().numpy(), global_step)\n",
    "                    val_score = eval_net(net, val_loader, device)\n",
    "                    scheduler.step(val_score)\n",
    "                    writer.add_scalar('learning_rate', optimizer.param_groups[0]['lr'], global_step)\n",
    "\n",
    "                    if net.n_classes > 1:\n",
    "                        logging.info('Validation cross entropy: {}'.format(val_score))\n",
    "                        writer.add_scalar('Loss/test', val_score, global_step)\n",
    "                    else:\n",
    "                        logging.info('Validation Dice Coeff: {}'.format(val_score))\n",
    "                        writer.add_scalar('Dice/test', val_score, global_step)\n",
    "\n",
    "                    writer.add_images('images', imgs, global_step)\n",
    "                    if net.n_classes == 1:\n",
    "                        writer.add_images('masks/true', true_masks, global_step)\n",
    "                        writer.add_images('masks/pred', torch.sigmoid(masks_pred) > 0.5, global_step)\n",
    "        \n",
    "        # Save checkpoint after every epoch\n",
    "        if save_cp:\n",
    "            try:\n",
    "                os.mkdir(dir_checkpoint)\n",
    "                logging.info('Created checkpoint directory')\n",
    "            except OSError:\n",
    "                pass\n",
    "            torch.save(net.state_dict(),\n",
    "                       dir_checkpoint + f'CP_epoch{epoch + 1}.pth')\n",
    "            logging.info(f'Checkpoint {epoch + 1} saved !')\n",
    "\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974229b6",
   "metadata": {},
   "source": [
    "#### Configure training parameters and device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296d24b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "# Automatically uses a GPU, if it is available to torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "logging.info(f'Using device {device}')\n",
    "\n",
    "# Change here to adapt to your data\n",
    "# n_channels = 3 for RGB images, < 3 for grayscale images\n",
    "# n_classes is the number of probabilities you want to get per pixel\n",
    "#   - For 1 class and background, use n_classes=1\n",
    "#   - For 2 classes, use n_classes=1\n",
    "#   - For N > 2 classes, use n_classes=N\n",
    "net = UNet(n_channels=3, n_classes=1, bilinear=True)\n",
    "logging.info(f'Network:\\n'\n",
    "     f'\\t{net.n_channels} input channels\\n'\n",
    "     f'\\t{net.n_classes} output channels (classes)\\n'\n",
    "     f'\\t{\"Bilinear\" if net.bilinear else \"Transposed conv\"} upscaling')\n",
    "net.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee092366",
   "metadata": {},
   "source": [
    "#### Call the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c82f2e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    train_net(net=net,\n",
    "              device=device)\n",
    "except KeyboardInterrupt:\n",
    "    torch.save(net.state_dict(), 'INTERRUPTED.pth')\n",
    "    logging.info('Saved interrupt')\n",
    "    try:\n",
    "        sys.exit(0)\n",
    "    except SystemExit:\n",
    "        os._exit(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
