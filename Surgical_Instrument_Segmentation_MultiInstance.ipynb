{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51ac3264",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d6650d",
   "metadata": {},
   "source": [
    "#### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b22edfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "\n",
    "# Change this path to wherever you installed the Pytorch-UNet module\n",
    "sys.path.append('C:/Users/Groh/Documents/GitHub/unet-nested-multiple-classification')\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "from unet import NestedUNet\n",
    "from unet import UNet\n",
    "from utils.dataset import BasicDataset\n",
    "from config import UNetConfig\n",
    "\n",
    "from losses import LovaszLossSoftmax\n",
    "from losses import LovaszLossHinge\n",
    "from losses import dice_coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d353a8",
   "metadata": {},
   "source": [
    "#### Assing absolute paths of image and mask folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e553b737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this path to the respective image and mask folders\n",
    "dir_img = 'C:/Users/Groh/Documents/GitHub/unet-nested-multiple-classification/data/images/'\n",
    "dir_mask = 'C:/Users/Groh/Documents/GitHub/unet-nested-multiple-classification/data/masks/'\n",
    "dir_checkpoint = 'C:/Users/Groh/Documents/GitHub/unet-nested-multiple-classification/data/checkpoints/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a828d",
   "metadata": {},
   "source": [
    "#### Prepare masks for multi instance segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e24db289",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_files = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ca8a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_files = len([f for f in os.listdir(dir_img)if os.path.isfile(os.path.join(dir_img, f))])\n",
    "\n",
    "if convert_files:\n",
    "    for i in range(num_files):\n",
    "        name = os.listdir(dir_img)[i]\n",
    "        file = dir_mask+name\n",
    "\n",
    "        # If a mask is missing, create a new, empty mask\n",
    "        if not os.path.isfile(file):\n",
    "            img = Image.open(dir_img+name)\n",
    "            width, height = img.size\n",
    "\n",
    "            img_new = Image.new('L', (width, height))\n",
    "            img_new.save(file, \"PNG\")\n",
    "\n",
    "        # Convert all images to 8-bit gray scales\n",
    "        img_grayscale = Image.open(file).convert('L')\n",
    "        img_grayscale.save(file)\n",
    "\n",
    "\n",
    "        # Check, whether more than background is visible in the mask\n",
    "        image_gray = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        unique = np.unique(image_gray.flatten())\n",
    "        if len(unique) > 1:\n",
    "            # For every pixel change gray-scale value according to categorical value\n",
    "            img = Image.open(file)\n",
    "            # Create pixel map\n",
    "            pixels = img.load()\n",
    "            for ii in range(img.size[0]): \n",
    "                for j in range(img.size[1]):\n",
    "                    if pixels[ii,j] == 52: # Atraum. Pinzette\n",
    "                        pixels[ii,j] = 1\n",
    "                    elif pixels[ii,j] == 113: # Nadelhalter\n",
    "                        pixels[ii,j] = 2\n",
    "    #                     elif pixels[i,j] = 52:\n",
    "    #                         pixels[i,j] = 1\n",
    "    #                     elif pixels[i,j] = 52:\n",
    "    #                         pixels[i,j] = 1\n",
    "    #                     elif pixels[i,j] = 52:\n",
    "    #                         pixels[i,j] = 1\n",
    "    #                     elif pixels[i,j] = 52:\n",
    "    #                         pixels[i,j] = 1\n",
    "    #                     elif pixels[i,j] = 52:\n",
    "    #                         pixels[i,j] = 1\n",
    "            img.save(file)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "60fb49dc",
   "metadata": {},
   "source": [
    "for i in range(num_files):\n",
    "    name = os.listdir(dir_img)[i]\n",
    "    file = dir_mask+name\n",
    "   \n",
    "    \n",
    "    image_gray = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    unique = np.unique(image_gray.flatten())\n",
    "    \n",
    "    img = Image.open(file)\n",
    "    img_array = np.array(img)\n",
    "    pictype = img_array.dtype\n",
    "    \n",
    "    picchannels = img_array.shape\n",
    "    \n",
    "    print(len(unique), unique, pictype, picchannels)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cfdc243b",
   "metadata": {},
   "source": [
    "img = Image.open(dir_img+name)\n",
    "\n",
    "img_array = np.array(img)\n",
    "\n",
    "pictype = img_array.dtype\n",
    "\n",
    "picchannels = img_array.shape\n",
    "\n",
    "print(pictype, picchannels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a61298",
   "metadata": {},
   "source": [
    "#### Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5523fc5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change UNet configuration if necessary\n",
    "# Also important to change n_channels and n_classes\n",
    "cfg = UNetConfig()\n",
    "\n",
    "# Training function\n",
    "def train_net(net, cfg):\n",
    "    dataset = BasicDataset(cfg.images_dir, cfg.masks_dir, cfg.scale)\n",
    "\n",
    "    val_percent = cfg.validation / 100\n",
    "    n_val = int(len(dataset) * val_percent)\n",
    "    n_train = len(dataset) - n_val\n",
    "    train, val = random_split(dataset, [n_train, n_val])\n",
    "\n",
    "    train_loader = DataLoader(train,\n",
    "                              batch_size=cfg.batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=8,\n",
    "                              pin_memory=True)\n",
    "    val_loader = DataLoader(val,\n",
    "                            batch_size=cfg.batch_size,\n",
    "                            shuffle=False,\n",
    "                            num_workers=8,\n",
    "                            pin_memory=True)\n",
    "\n",
    "    writer = SummaryWriter(comment=f'LR_{cfg.lr}_BS_{cfg.batch_size}_SCALE_{cfg.scale}')\n",
    "    global_step = 0\n",
    "\n",
    "    logging.info(f'''Starting training:\n",
    "        Epochs:          {cfg.epochs}\n",
    "        Batch size:      {cfg.batch_size}\n",
    "        Learning rate:   {cfg.lr}\n",
    "        Optimizer:       {cfg.optimizer}\n",
    "        Training size:   {n_train}\n",
    "        Validation size: {n_val}\n",
    "        Checkpoints:     {cfg.save_cp}\n",
    "        Device:          {device.type}\n",
    "        Images scaling:  {cfg.scale}\n",
    "    ''')\n",
    "\n",
    "    if cfg.optimizer == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(),\n",
    "                               lr=cfg.lr)\n",
    "    elif cfg.optimizer == 'RMSprop':\n",
    "        optimizer = optim.RMSprop(net.parameters(),\n",
    "                                  lr=cfg.lr,\n",
    "                                  weight_decay=cfg.weight_decay)\n",
    "    else:\n",
    "        optimizer = optim.SGD(net.parameters(),\n",
    "                              lr=cfg.lr,\n",
    "                              momentum=cfg.momentum,\n",
    "                              weight_decay=cfg.weight_decay,\n",
    "                              nesterov=cfg.nesterov)\n",
    "\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                               milestones=cfg.lr_decay_milestones,\n",
    "                                               gamma = cfg.lr_decay_gamma)\n",
    "    if cfg.n_classes > 1:\n",
    "        criterion = LovaszLossSoftmax()\n",
    "    else:\n",
    "        criterion = LovaszLossHinge()\n",
    "\n",
    "    for epoch in range(cfg.epochs):\n",
    "        net.train()\n",
    "\n",
    "        epoch_loss = 0\n",
    "        with tqdm(total=n_train, desc=f'Epoch {epoch + 1}/{cfg.epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                batch_imgs = batch['image']\n",
    "                batch_masks = batch['mask']\n",
    "                assert batch_imgs.shape[1] == cfg.n_channels, \\\n",
    "                        f'Network has been defined with {cfg.n_channels} input channels, ' \\\n",
    "                        f'but loaded images have {batch_imgs.shape[1]} channels. Please check that ' \\\n",
    "                        'the images are loaded correctly.'\n",
    "\n",
    "                batch_imgs = batch_imgs.to(device=device, dtype=torch.float32)\n",
    "                mask_type = torch.float32 if cfg.n_classes == 1 else torch.long\n",
    "                batch_masks = batch_masks.to(device=device, dtype=mask_type)\n",
    "\n",
    "                inference_masks = net(batch_imgs)\n",
    "\n",
    "                if cfg.n_classes == 1:\n",
    "                    inferences = inference_masks.squeeze(1)\n",
    "                    masks = batch_masks.squeeze(1)\n",
    "                else:\n",
    "                    inferences = inference_masks\n",
    "                    masks = batch_masks\n",
    "\n",
    "                if cfg.deepsupervision:\n",
    "                    loss = 0\n",
    "                    for inference_mask in inferences:\n",
    "                        loss += criterion(inference_mask, masks)\n",
    "                    loss /= len(inferences)\n",
    "                else:\n",
    "                    loss = criterion(inferences, masks)\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                writer.add_scalar('Loss/train', loss.item(), global_step)\n",
    "                writer.add_scalar('model/lr', optimizer.param_groups[0]['lr'], global_step)\n",
    "\n",
    "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                pbar.update(batch_imgs.shape[0])\n",
    "                global_step += 1\n",
    "\n",
    "                if global_step % (len(dataset) // (1 * cfg.batch_size)) == 0:\n",
    "                    val_score = eval_net(net, val_loader, device, n_val, cfg)\n",
    "                    if cfg.n_classes > 1:\n",
    "                        logging.info('Validation cross entropy: {}'.format(val_score))\n",
    "                        writer.add_scalar('CrossEntropy/test', val_score, global_step)\n",
    "                    else:\n",
    "                        logging.info('Validation Dice Coeff: {}'.format(val_score))\n",
    "                        writer.add_scalar('Dice/test', val_score, global_step)\n",
    "\n",
    "                    writer.add_images('images', batch_imgs, global_step)\n",
    "                    if cfg.deepsupervision:\n",
    "                            inference_masks = inference_masks[-1]\n",
    "                    if cfg.n_classes == 1:\n",
    "                        # writer.add_images('masks/true', batch_masks, global_step)\n",
    "                        inference_mask = torch.sigmoid(inference_masks) > cfg.out_threshold\n",
    "                        writer.add_images('masks/inference',\n",
    "                                          inference_mask,\n",
    "                                          global_step)\n",
    "                    else:\n",
    "                        # writer.add_images('masks/true', batch_masks, global_step)\n",
    "                        ids = inference_masks.shape[1]  # N x C x H x W\n",
    "                        inference_masks = torch.chunk(inference_masks, ids, dim=1)\n",
    "                        for idx in range(0, len(inference_masks)):\n",
    "                            inference_mask = torch.sigmoid(inference_masks[idx]) > cfg.out_threshold\n",
    "                            writer.add_images('masks/inference_'+str(idx),\n",
    "                                              inference_mask,\n",
    "                                              global_step)\n",
    "\n",
    "        if cfg.save_cp:\n",
    "            try:\n",
    "                os.mkdir(cfg.checkpoints_dir)\n",
    "                logging.info('Created checkpoint directory')\n",
    "            except OSError:\n",
    "                pass\n",
    "\n",
    "            ckpt_name = 'epoch_' + str(epoch + 1) + '.pth'\n",
    "            torch.save(net.state_dict(),\n",
    "                       osp.join(cfg.checkpoints_dir, ckpt_name))\n",
    "            logging.info(f'Checkpoint {epoch + 1} saved !')\n",
    "\n",
    "    writer.close()\n",
    "    \n",
    "\n",
    "# Evaluation function\n",
    "def eval_net(net, loader, device, n_val, cfg):\n",
    "    \"\"\"\n",
    "    Evaluation without the densecrf with the dice coefficient\n",
    "\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    tot = 0\n",
    "\n",
    "    with tqdm(total=n_val, desc='Validation round', unit='img', leave=False) as pbar:\n",
    "        for batch in loader:\n",
    "            imgs = batch['image']\n",
    "            true_masks = batch['mask']\n",
    "\n",
    "            imgs = imgs.to(device=device, dtype=torch.float32)\n",
    "            mask_type = torch.float32 if cfg.n_classes == 1 else torch.long\n",
    "            true_masks = true_masks.to(device=device, dtype=mask_type)\n",
    "\n",
    "            # compute loss\n",
    "            if cfg.deepsupervision:\n",
    "                masks_preds = net(imgs)\n",
    "                loss = 0\n",
    "                for masks_pred in masks_preds:\n",
    "                    tot_cross_entropy = 0\n",
    "                    for true_mask, pred in zip(true_masks, masks_pred):\n",
    "                        pred = (pred > cfg.out_threshold).float()\n",
    "                        if cfg.n_classes > 1:\n",
    "                            sub_cross_entropy = F.cross_entropy(pred.unsqueeze(dim=0), true_mask.unsqueeze(dim=0).squeeze(1)).item()\n",
    "                        else:\n",
    "                            sub_cross_entropy = dice_coeff(pred, true_mask.squeeze(dim=1)).item()\n",
    "                        tot_cross_entropy += sub_cross_entropy\n",
    "                    tot_cross_entropy = tot_cross_entropy / len(masks_preds)\n",
    "                    tot += tot_cross_entropy\n",
    "            else:\n",
    "                masks_pred = net(imgs)\n",
    "                for true_mask, pred in zip(true_masks, masks_pred):\n",
    "                    pred = (pred > cfg.out_threshold).float()\n",
    "                    if cfg.n_classes > 1:\n",
    "                        tot += F.cross_entropy(pred.unsqueeze(dim=0), true_mask.unsqueeze(dim=0).squeeze(1)).item()\n",
    "                    else:\n",
    "                        tot += dice_coeff(pred, true_mask.squeeze(dim=1)).item()\n",
    "\n",
    "            pbar.update(imgs.shape[0])\n",
    "\n",
    "    return tot / n_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fecb5df",
   "metadata": {},
   "source": [
    "#### Configure training parameters and device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "296d24b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using device cuda\n",
      "INFO: Network:\n",
      "\tNestedUNet model\n",
      "\t3 input channels\n",
      "\t3 output channels (classes)\n",
      "\tBilinear upscaling\n",
      "INFO: Model loaded from C:/Users/Groh/Documents/GitHub/unet-nested-multiple-classification/data/checkpoints/epoch_1000.pth\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "# Automatically uses a GPU, if it is available to torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "logging.info(f'Using device {device}')\n",
    "\n",
    "net = eval(cfg.model)(cfg)\n",
    "logging.info(f'Network:\\n'\n",
    "             f'\\t{cfg.model} model\\n'\n",
    "             f'\\t{cfg.n_channels} input channels\\n'\n",
    "             f'\\t{cfg.n_classes} output channels (classes)\\n'\n",
    "             f'\\t{\"Bilinear\" if cfg.bilinear else \"Dilated conv\"} upscaling')\n",
    "\n",
    "if cfg.load:\n",
    "    net.load_state_dict(\n",
    "        torch.load(cfg.load, map_location=device)\n",
    "    )\n",
    "    logging.info(f'Model loaded from {cfg.load}')\n",
    "\n",
    "net.to(device=device);\n",
    "# faster convolutions, but more memory\n",
    "# cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dbf6ba",
   "metadata": {},
   "source": [
    "#### Call the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c82f2e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    train_net(net=net, cfg=cfg)\n",
    "except KeyboardInterrupt:\n",
    "    torch.save(net.state_dict(), 'INTERRUPTED.pth')\n",
    "    logging.info('Saved interrupt')\n",
    "    try:\n",
    "        sys.exit(0)\n",
    "    except SystemExit:\n",
    "        os._exit(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
